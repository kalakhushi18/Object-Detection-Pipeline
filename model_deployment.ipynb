{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "from sagemaker import image_uris\n",
    "\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    region = sess.boto_region_name, framework = \"object-detection\", version = \"1\"\n",
    ")\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating endpoint and model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.model.Model(\n",
    "image_uri = training_image,\n",
    "model_data = 'S3_URI_best model path',\n",
    "role = role    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = ''\n",
    "\n",
    "deployment = model.deploy(          #deploying model in Jupyterlab AWS\n",
    "initial_instance_count = 1,\n",
    "instance_type = \"ml.m4.xlarge\",  # no gpu require\n",
    "endpoint_name = endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import boto3\n",
    "runtime = boto3.client(service_name = \"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg#pyplot\n",
    "\n",
    "\n",
    "def visualize_detection(img_file, dets, thresh = 0.6):\n",
    "    img = mpimg.imread(img_file)\n",
    "    plt.imshow(img)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    colors = dict()\n",
    "    num_detections = 0\n",
    "    for det in dets:\n",
    "        (klass,score,x0,y0,x1,y1) = det #0\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        num_detections +=1\n",
    "        cls_id = int(klass)#1\n",
    "        if cls_id not in colors:\n",
    "            colors[cls_id] = (random.random(),random.random(),random.random()) #(0.1,0.5,0.4)\n",
    "        xmin = int(x0*width)\n",
    "        ymin = int(y0*height)\n",
    "        xmax = int(x1*width)\n",
    "        ymax = int(y1*height) \n",
    "        \n",
    "        \n",
    "        rect = plt.Rectangle(\n",
    "            (xmin,ymin),\n",
    "            xmax - xmin,\n",
    "            ymax - ymin,\n",
    "            fill = False,\n",
    "            edgecolor = colors[cls_id],\n",
    "            linewidth = 3.5\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.gca().text(\n",
    "        xmin,\n",
    "        ymin-2,\n",
    "        \"{:.3f}\".format(score),\n",
    "        bbox = dict(facecolor = colors[cls_id], alpha = 0.5),\n",
    "        fontsize = 12,\n",
    "        color = \"white\"\n",
    "        )\n",
    "    print(\"Number of detections\" + str(num_detections))\n",
    "    plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plastic_prediction(filename, ep, thresh = 0.3):\n",
    "    b = \"\"\n",
    "    with open(filename, \"rb\" ) as image:\n",
    "        f = image.read()\n",
    "        b = bytearray(f)\n",
    "    endpoint_response = runtime.invoke_endpoint(EndpointName = ep, ContentType = \"image/jpeg\", Body = b)\n",
    "    results = endpoint_response[\"Body\"].read()\n",
    "    detections = json.loads(results)\n",
    "    \n",
    "    \n",
    "    visualize_detection(filename, detections['prediction'], thresh)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
